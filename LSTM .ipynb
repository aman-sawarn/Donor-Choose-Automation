{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "1. Download the preprocessed DonorsChoose data from here <a href='https://drive.google.com/file/d/1GU3LIJJ3zS1xLXXe-sdItSJHtI5txjVO/view?usp=sharing'>Dataset</a>\n",
    "2. Split the data into train, cv, and test\n",
    "3. After step 2 you have to train 3 types of models as discussed below. \n",
    "4. For all the model use <a href='https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics'>'auc'</a> as a metric. check <a href='https://datascience.stackexchange.com/a/20192'>this</a> for using auc as a metric. you need to print the AUC value for each epoch. Note: you should NOT use the tf.metric.auc\n",
    "5. You are free to choose any number of layers/hiddden units but you have to use same type of architectures shown below. \n",
    "6. You can use any one of the optimizers and choice of Learning rate and momentum, resources: <a href='http://cs231n.github.io/neural-networks-3/'>cs231n class notes</a>, <a href='https://www.youtube.com/watch?v=hd_KFJ5ktUc'>cs231n class video</a>. \n",
    "7. You should Save the best model weights.\n",
    "8. For all the model's use <a href='https://www.youtube.com/watch?v=2U6Jl7oqRkM'>TensorBoard</a> and plot the Metric value and Loss with epoch. While submitting, take a screenshot of plots and include those images in .ipynb notebook and PDF. \n",
    "9. Use Categorical Cross Entropy as Loss to minimize.\n",
    "10. try to get AUC more than 0.8 for atleast one model\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-1\n",
    "\n",
    "Build and Train deep neural network as shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/w395Yk9.png'>\n",
    "ref: https://i.imgur.com/w395Yk9.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Input_seq_total_text_data__ --- You have to give Total text data columns. After this use the Embedding layer to get word vectors. Use given predefined glove word vectors, don't train any word vectors. After this use LSTM and get the LSTM output and Flatten that output. \n",
    "- __Input_school_state__ --- Give 'school_state' column as input to embedding layer and Train the Keras Embedding layer. \n",
    "- __Project_grade_category__  --- Give 'project_grade_category' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_clean_categories__ --- Give 'input_clean_categories' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_clean_subcategories__ --- Give 'input_clean_subcategories' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_clean_subcategories__ --- Give 'input_teacher_prefix' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_remaining_teacher_number_of_previously_posted_projects._resource_summary_contains_numerical_digits._price._quantity__ ---concatenate remaining columns and add a Dense layer after that. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For LSTM, you can choose your sequence padding methods on your own or you can train your LSTM without padding, there is no restriction on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of embedding layer for a categorical columns. In below code all are dummy values, we gave only for referance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work\n",
    "input_layer = Input(shape=(n,))\n",
    "embedding = Embedding(no_1, no_2, input_length=n)(input_layer)\n",
    "flatten = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Go through this blog, if you have any doubt on using predefined Embedding values in Embedding layer - https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "### 2. Please go through this link https://keras.io/getting-started/functional-api-guide/ and check the 'Multi-input and multi-output models' then you will get to know how to give multiple inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same model as above but for 'input_seq_total_text_data' give only some words in the sentance not all the words. Filter the words as below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "1. Train the TF-IDF on the Train data feature 'essay' <br>\n",
    "2. Get the idf value for each word we have in the train data. <br>\n",
    "3. Remove the low idf value and high idf value words from our data. Do some analysis on the Idf values and based on those values choose the low and high threshold value. Because very frequent words and very very rare words don't give much information. (you can plot a box plots and take only the idf scores within IQR range and corresponding words)<br>\n",
    "4. Train the LSTM after removing the Low and High idf value words. (In model-1 Train on total data but in Model-2 train on data after removing some words based on IDF values)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/fkQ8nGo.png'>\n",
    "ref: https://i.imgur.com/fkQ8nGo.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- __input_seq_total_text_data__: <br>\n",
    "<pre>\n",
    "    . Use text column('essay'), and use the Embedding layer to get word vectors. <br>\n",
    "    . Use given predefined glove word vectors, don't train any word vectors. <br>\n",
    "    . Use LSTM that is given above, get the LSTM output and Flatten that output. <br>\n",
    "    . You are free to preprocess the input text as you needed. <br>\n",
    "</pre>\n",
    "- __Other_than_text_data__:<br>\n",
    "<pre>\n",
    "    . Convert all your Categorical values to onehot coded and then concatenate all these onehot vectors <br>\n",
    "    . Neumerical values and use <a href='https://keras.io/getting-started/sequential-model-guide/#sequence-classification-with-1d-convolutions'>CNN1D</a> as shown in above figure. <br>\n",
    "    . You are free to choose all CNN parameters like kernel sizes, stride.<br>\n",
    "    \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard module is not an IPython extension.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Tensorboard\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Input, Flatten, concatenate\n",
    "from keras.layers import LSTM, Conv1D, MaxPool1D, LeakyReLU, ELU, SpatialDropout1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"F:\\Donors Choose preprocessed_data.csv\")\n",
    "# project_data = pd.read_csv(path + 'train_data.csv')\n",
    "# resource_data = pd.read_csv(path + 'resources.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>725.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>213.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>329.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>481.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>17.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state teacher_prefix project_grade_category  \\\n",
       "0           ca            mrs          grades_prek_2   \n",
       "1           ut             ms             grades_3_5   \n",
       "2           ca            mrs          grades_prek_2   \n",
       "3           ga            mrs          grades_prek_2   \n",
       "4           wa            mrs             grades_3_5   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            53                    1   \n",
       "1                                             4                    1   \n",
       "2                                            10                    1   \n",
       "3                                             2                    1   \n",
       "4                                             2                    1   \n",
       "\n",
       "    clean_categories                 clean_subcategories  \\\n",
       "0       math_science  appliedsciences health_lifescience   \n",
       "1       specialneeds                        specialneeds   \n",
       "2  literacy_language                            literacy   \n",
       "3    appliedlearning                    earlydevelopment   \n",
       "4  literacy_language                            literacy   \n",
       "\n",
       "                                               essay   price  \n",
       "0  i fortunate enough use fairy tale stem kits cl...  725.05  \n",
       "1  imagine 8 9 years old you third grade classroo...  213.03  \n",
       "2  having class 24 students comes diverse learner...  329.00  \n",
       "3  i recently read article giving students choice...  481.04  \n",
       "4  my students crave challenge eat obstacles brea...   17.74  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_state', 'teacher_prefix', 'project_grade_category',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'clean_categories', 'clean_subcategories', 'essay', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of data points in train data (109248, 9)\n",
      "________________________________________________________________________________________________________________________\n",
      "The features for data:   Index(['school_state', 'teacher_prefix', 'project_grade_category',\n",
      "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
      "       'clean_categories', 'clean_subcategories', 'essay', 'price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"No of data points in train data\", df.shape)\n",
    "print('_'*120)\n",
    "print(\"The features for data:  \", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    92706\n",
       "0    16542\n",
       "Name: project_is_approved, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"project_is_approved\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grades_prek_2    44225\n",
       "grades_3_5       37137\n",
       "grades_6_8       16923\n",
       "grades_9_12      10963\n",
       "Name: project_grade_category, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['project_grade_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grades_prek_2    44225\n",
       "grades_3_5       37137\n",
       "grades_6_8       16923\n",
       "grades_9_12      10963\n",
       "Name: project_grade_category, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/36383821/pandas-dataframe-apply-function-to-column-strings-based-on-other-column-value\n",
    "df['project_grade_category'] = df['project_grade_category'].str.replace(' ','_')\n",
    "df['project_grade_category'] = df['project_grade_category'].str.replace('-','_')\n",
    "df['project_grade_category'] = df['project_grade_category'].str.lower()\n",
    "df['project_grade_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "number of Null values 0\n"
     ]
    }
   ],
   "source": [
    "# null values\n",
    "print(df['teacher_prefix'].isnull().values.any())\n",
    "print(\"number of Null values\",df['teacher_prefix'].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "literacy_language                       23655\n",
       "math_science                            17072\n",
       "literacy_language math_science          14636\n",
       "health_sports                           10177\n",
       "music_arts                               5180\n",
       "specialneeds                             4226\n",
       "literacy_language specialneeds           3961\n",
       "appliedlearning                          3771\n",
       "math_science literacy_language           2289\n",
       "appliedlearning literacy_language        2191\n",
       "history_civics                           1851\n",
       "math_science specialneeds                1840\n",
       "literacy_language music_arts             1757\n",
       "math_science music_arts                  1642\n",
       "appliedlearning specialneeds             1467\n",
       "history_civics literacy_language         1421\n",
       "health_sports specialneeds               1391\n",
       "warmth care_hunger                       1309\n",
       "math_science appliedlearning             1220\n",
       "appliedlearning math_science             1052\n",
       "literacy_language history_civics          809\n",
       "health_sports literacy_language           803\n",
       "appliedlearning music_arts                758\n",
       "math_science history_civics               652\n",
       "literacy_language appliedlearning         636\n",
       "appliedlearning health_sports             608\n",
       "math_science health_sports                414\n",
       "history_civics math_science               322\n",
       "history_civics music_arts                 312\n",
       "specialneeds music_arts                   302\n",
       "health_sports math_science                271\n",
       "history_civics specialneeds               252\n",
       "health_sports appliedlearning             192\n",
       "appliedlearning history_civics            178\n",
       "health_sports music_arts                  155\n",
       "music_arts specialneeds                   138\n",
       "literacy_language health_sports            72\n",
       "health_sports history_civics               43\n",
       "specialneeds health_sports                 42\n",
       "history_civics appliedlearning             42\n",
       "health_sports warmth care_hunger           23\n",
       "specialneeds warmth care_hunger            23\n",
       "music_arts health_sports                   19\n",
       "music_arts history_civics                  18\n",
       "history_civics health_sports               13\n",
       "math_science warmth care_hunger            11\n",
       "music_arts appliedlearning                 10\n",
       "appliedlearning warmth care_hunger         10\n",
       "literacy_language warmth care_hunger        9\n",
       "music_arts warmth care_hunger               2\n",
       "history_civics warmth care_hunger           1\n",
       "Name: clean_categories, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "literacy_language                     23655\n",
       "math_science                          17072\n",
       "literacy_languagemath_science         14636\n",
       "health_sports                         10177\n",
       "music_arts                             5180\n",
       "specialneeds                           4226\n",
       "literacy_languagespecialneeds          3961\n",
       "appliedlearning                        3771\n",
       "math_scienceliteracy_language          2289\n",
       "appliedlearningliteracy_language       2191\n",
       "history_civics                         1851\n",
       "math_sciencespecialneeds               1840\n",
       "literacy_languagemusic_arts            1757\n",
       "math_sciencemusic_arts                 1642\n",
       "appliedlearningspecialneeds            1467\n",
       "history_civicsliteracy_language        1421\n",
       "health_sportsspecialneeds              1391\n",
       "warmthcare_hunger                      1309\n",
       "math_scienceappliedlearning            1220\n",
       "appliedlearningmath_science            1052\n",
       "literacy_languagehistory_civics         809\n",
       "health_sportsliteracy_language          803\n",
       "appliedlearningmusic_arts               758\n",
       "math_sciencehistory_civics              652\n",
       "literacy_languageappliedlearning        636\n",
       "appliedlearninghealth_sports            608\n",
       "math_sciencehealth_sports               414\n",
       "history_civicsmath_science              322\n",
       "history_civicsmusic_arts                312\n",
       "specialneedsmusic_arts                  302\n",
       "health_sportsmath_science               271\n",
       "history_civicsspecialneeds              252\n",
       "health_sportsappliedlearning            192\n",
       "appliedlearninghistory_civics           178\n",
       "health_sportsmusic_arts                 155\n",
       "music_artsspecialneeds                  138\n",
       "literacy_languagehealth_sports           72\n",
       "health_sportshistory_civics              43\n",
       "specialneedshealth_sports                42\n",
       "history_civicsappliedlearning            42\n",
       "health_sportswarmthcare_hunger           23\n",
       "specialneedswarmthcare_hunger            23\n",
       "music_artshealth_sports                  19\n",
       "music_artshistory_civics                 18\n",
       "history_civicshealth_sports              13\n",
       "math_sciencewarmthcare_hunger            11\n",
       "music_artsappliedlearning                10\n",
       "appliedlearningwarmthcare_hunger         10\n",
       "literacy_languagewarmthcare_hunger        9\n",
       "music_artswarmthcare_hunger               2\n",
       "history_civicswarmthcare_hunger           1\n",
       "Name: clean_categories, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_categories'] = df['clean_categories'].str.replace(' The ','')\n",
    "df['clean_categories'] = df['clean_categories'].str.replace(' ','')\n",
    "df['clean_categories'] = df['clean_categories'].str.replace('&','_')\n",
    "df['clean_categories'] = df['clean_categories'].str.replace(',','_')\n",
    "df['clean_categories'] = df['clean_categories'].str.lower()\n",
    "df['clean_categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mrs        57272\n",
       "ms         38955\n",
       "mr         10648\n",
       "teacher     2360\n",
       "dr            13\n",
       "Name: teacher_prefix, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['teacher_prefix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "literacy                                   9486\n",
       "literacy mathematics                       8325\n",
       "literature_writing mathematics             5923\n",
       "literacy literature_writing                5571\n",
       "mathematics                                5379\n",
       "literature_writing                         4501\n",
       "specialneeds                               4226\n",
       "health_wellness                            3583\n",
       "appliedsciences mathematics                3399\n",
       "appliedsciences                            2492\n",
       "literacy specialneeds                      2440\n",
       "gym_fitness health_wellness                2264\n",
       "esl literacy                               2234\n",
       "visualarts                                 2217\n",
       "music                                      1472\n",
       "warmth care_hunger                         1309\n",
       "literature_writing specialneeds            1306\n",
       "gym_fitness                                1195\n",
       "health_wellness specialneeds               1189\n",
       "mathematics specialneeds                   1187\n",
       "environmentalscience                       1079\n",
       "teamsports                                 1061\n",
       "appliedsciences environmentalscience        984\n",
       "environmentalscience health_lifescience     964\n",
       "music performingarts                        948\n",
       "earlydevelopment                            905\n",
       "environmentalscience mathematics            838\n",
       "other                                       831\n",
       "health_lifescience                          827\n",
       "health_wellness nutritioneducation          797\n",
       "                                           ... \n",
       "socialsciences teamsports                     2\n",
       "environmentalscience teamsports               2\n",
       "financialliteracy health_wellness             2\n",
       "civics_government health_wellness             2\n",
       "foreignlanguages gym_fitness                  2\n",
       "visualarts warmth care_hunger                 2\n",
       "college_careerprep warmth care_hunger         1\n",
       "civics_government foreignlanguages            1\n",
       "economics music                               1\n",
       "economics nutritioneducation                  1\n",
       "gym_fitness socialsciences                    1\n",
       "esl economics                                 1\n",
       "history_geography warmth care_hunger          1\n",
       "esl teamsports                                1\n",
       "literature_writing nutritioneducation         1\n",
       "communityservice music                        1\n",
       "gym_fitness parentinvolvement                 1\n",
       "economics other                               1\n",
       "extracurricular financialliteracy             1\n",
       "gym_fitness warmth care_hunger                1\n",
       "other warmth care_hunger                      1\n",
       "parentinvolvement teamsports                  1\n",
       "communityservice gym_fitness                  1\n",
       "civics_government parentinvolvement           1\n",
       "civics_government nutritioneducation          1\n",
       "parentinvolvement warmth care_hunger          1\n",
       "financialliteracy performingarts              1\n",
       "communityservice financialliteracy            1\n",
       "financialliteracy foreignlanguages            1\n",
       "economics foreignlanguages                    1\n",
       "Name: clean_subcategories, Length: 401, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_subcategories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca    15388\n",
       "tx     7396\n",
       "ny     7318\n",
       "fl     6185\n",
       "nc     5091\n",
       "il     4350\n",
       "ga     3963\n",
       "sc     3936\n",
       "mi     3161\n",
       "pa     3109\n",
       "in     2620\n",
       "mo     2576\n",
       "oh     2467\n",
       "la     2394\n",
       "ma     2389\n",
       "wa     2334\n",
       "ok     2276\n",
       "nj     2237\n",
       "az     2147\n",
       "va     2045\n",
       "wi     1827\n",
       "al     1762\n",
       "ut     1731\n",
       "tn     1688\n",
       "ct     1663\n",
       "md     1514\n",
       "nv     1367\n",
       "ms     1323\n",
       "ky     1304\n",
       "or     1242\n",
       "mn     1208\n",
       "co     1111\n",
       "ar     1049\n",
       "id      693\n",
       "ia      666\n",
       "ks      634\n",
       "nm      557\n",
       "dc      516\n",
       "hi      507\n",
       "me      505\n",
       "wv      503\n",
       "nh      348\n",
       "ak      345\n",
       "de      343\n",
       "ne      309\n",
       "sd      300\n",
       "ri      285\n",
       "mt      245\n",
       "nd      143\n",
       "wy       98\n",
       "vt       80\n",
       "Name: school_state, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['school_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_state', 'teacher_prefix', 'project_grade_category',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'clean_categories', 'clean_subcategories', 'essay', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i fortunate enough use fairy tale stem kits cl...\n",
       "1    imagine 8 9 years old you third grade classroo...\n",
       "2    having class 24 students comes diverse learner...\n",
       "3    i recently read article giving students choice...\n",
       "4    my students crave challenge eat obstacles brea...\n",
       "Name: essay, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['essay'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
